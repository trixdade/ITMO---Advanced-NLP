{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "174b14f8-fc03-4722-99e5-52356eb13ed3",
   "metadata": {},
   "source": [
    "# [3 points] **Part 1: Loading the dataset & Looking at it**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06265c20-efea-4e11-b419-6ab0471dee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from math import ceil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d30211a-85dd-4c41-8f6e-f53b044df71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19aad33b-c92d-4244-a7bb-b705134aba6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404290 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404290 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f090c3-6175-4fe1-aeb3-36a50009ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['question1'].isna()]\n",
    "data = data[~data['question2'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c382aa-26b6-4afe-b408-39360a349409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404285</th>\n",
       "      <td>404285</td>\n",
       "      <td>433578</td>\n",
       "      <td>379845</td>\n",
       "      <td>How many keywords are there in the Racket prog...</td>\n",
       "      <td>How many keywords are there in PERL Programmin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404286</th>\n",
       "      <td>404286</td>\n",
       "      <td>18840</td>\n",
       "      <td>155606</td>\n",
       "      <td>Do you believe there is life after death?</td>\n",
       "      <td>Is it true that there is life after death?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404287</th>\n",
       "      <td>404287</td>\n",
       "      <td>537928</td>\n",
       "      <td>537929</td>\n",
       "      <td>What is one coin?</td>\n",
       "      <td>What's this coin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404288</th>\n",
       "      <td>404288</td>\n",
       "      <td>537930</td>\n",
       "      <td>537931</td>\n",
       "      <td>What is the approx annual cost of living while...</td>\n",
       "      <td>I am having little hairfall problem but I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404289</th>\n",
       "      <td>404289</td>\n",
       "      <td>537932</td>\n",
       "      <td>537933</td>\n",
       "      <td>What is like to have sex with cousin?</td>\n",
       "      <td>What is it like to have sex with your cousin?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404287 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "0            0       1       2   \n",
       "1            1       3       4   \n",
       "2            2       5       6   \n",
       "3            3       7       8   \n",
       "4            4       9      10   \n",
       "...        ...     ...     ...   \n",
       "404285  404285  433578  379845   \n",
       "404286  404286   18840  155606   \n",
       "404287  404287  537928  537929   \n",
       "404288  404288  537930  537931   \n",
       "404289  404289  537932  537933   \n",
       "\n",
       "                                                question1  \\\n",
       "0       What is the step by step guide to invest in sh...   \n",
       "1       What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2       How can I increase the speed of my internet co...   \n",
       "3       Why am I mentally very lonely? How can I solve...   \n",
       "4       Which one dissolve in water quikly sugar, salt...   \n",
       "...                                                   ...   \n",
       "404285  How many keywords are there in the Racket prog...   \n",
       "404286          Do you believe there is life after death?   \n",
       "404287                                  What is one coin?   \n",
       "404288  What is the approx annual cost of living while...   \n",
       "404289              What is like to have sex with cousin?   \n",
       "\n",
       "                                                question2  is_duplicate  \n",
       "0       What is the step by step guide to invest in sh...             0  \n",
       "1       What would happen if the Indian government sto...             0  \n",
       "2       How can Internet speed be increased by hacking...             0  \n",
       "3       Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4                 Which fish would survive in salt water?             0  \n",
       "...                                                   ...           ...  \n",
       "404285  How many keywords are there in PERL Programmin...             0  \n",
       "404286         Is it true that there is life after death?             1  \n",
       "404287                                  What's this coin?             0  \n",
       "404288  I am having little hairfall problem but I want...             0  \n",
       "404289      What is it like to have sex with your cousin?             0  \n",
       "\n",
       "[404287 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[~data['question1'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d58740c-0f7b-4c1e-a412-910012e6d266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What is the step by step guide to invest in share market in india?\n",
      "Q2: What is the step by step guide to invest in share market?\n"
     ]
    }
   ],
   "source": [
    "# non-duplicate example\n",
    "questions = data[data['is_duplicate'] == 0].loc[0]\n",
    "print(f'Q1: {questions.question1}\\nQ2: {questions.question2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88959f10-4a65-46e4-ade1-693e5d63a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: How can I be a good geologist?\n",
      "Q2: What should I do to be a great geologist?\n"
     ]
    }
   ],
   "source": [
    "# duplicate example\n",
    "questions = data[data['is_duplicate'] == 1].loc[7]\n",
    "print(f'Q1: {questions.question1}\\nQ2: {questions.question2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4dcc38-8b11-4051-b82f-3324a0da5614",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, stratify=data['is_duplicate'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bba2352-1ef3-41f9-8feb-e1c6c27e575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dublicates:  111947\n",
      "Number of non-dublicates:  191268\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of dublicates: \", train.query('is_duplicate == 1').shape[0])\n",
    "print(\"Number of non-dublicates: \", train.query('is_duplicate == 0').shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b25c572-6a5f-4926-8744-b5de667dbb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of questions:  606430\n",
      "Number of unique questions:  142568\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of questions: \", 2 * train.shape[0])\n",
    "print(\"Number of unique questions: \", 2 * train.shape[0] - train.qid1.unique().shape[0] - train.qid2.unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5de9e9c-d58e-41b4-817b-93a3698ce051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 111947\n"
     ]
    }
   ],
   "source": [
    "train_idx = train[train['is_duplicate'] == 1].id.tolist()\n",
    "print(f'Number of training examples: {len(train_idx)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07def689-0b3c-48d2-acfd-a57e5f430074",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train_data = np.array(train.loc[train_idx, 'question1'])\n",
    "q2_train_data = np.array(train.loc[train_idx, 'question2'])\n",
    "q1_test_data = np.array(test['question1'])\n",
    "q2_test_data = np.array(test['question2'])\n",
    "\n",
    "q1_train = np.empty_like(q1_train_data)\n",
    "q2_train = np.empty_like(q2_train_data)\n",
    "q1_test = np.empty_like(q1_test_data)\n",
    "q2_test = np.empty_like(q2_test_data)\n",
    "\n",
    "y_test  = np.array(test['is_duplicate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "829756ce-e937-4c1b-b842-ea1c654ec375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Can a Gemini man and a Gemini woman have a successful relationship? Or are they incompatible?',\n",
       "        'How can I delete my own question from Quora?',\n",
       "        'Why are there still people who think that the Earth is flat?',\n",
       "        'What should I do to concentrate more on my studies?',\n",
       "        'How can one stop caring too much?'], dtype=object),\n",
       " array(['What is the compatibility of a Gemini man and a Gemini woman, romantically?',\n",
       "        'Can I delete all the questions I asked on Quora?',\n",
       "        'Why do some people currently believe the earth is flat?',\n",
       "        'How do I concentrate in study?',\n",
       "        'What should I do to stop myself from caring too much?'],\n",
       "       dtype=object))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_train_data[:5], q2_train_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6258dfb-b763-4aba-9abb-c26ced6a73dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Роман\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is:  36378\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "vocab = defaultdict(lambda: 0)\n",
    "vocab['<PAD>'] = 1\n",
    "\n",
    "for idx in range(len(q1_train_data)):\n",
    "    q1_train[idx] = nltk.word_tokenize(q1_train_data[idx])\n",
    "    q2_train[idx] = nltk.word_tokenize(q2_train_data[idx])\n",
    "    q = q1_train[idx] + q2_train[idx]\n",
    "    for word in q:\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab) + 1\n",
    "print('Vocabulary size is: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36ce74c-64ff-4a1f-a76c-f68aa1a8aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing test\n",
    "\n",
    "for idx in range(len(q1_test_data)): \n",
    "    q1_test[idx] = nltk.word_tokenize(q1_test_data[idx])\n",
    "    q2_test[idx] = nltk.word_tokenize(q2_test_data[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af3f15de-58c1-46af-97e0-0eed8a380580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['Can', 'a', 'Gemini', 'man', 'and', 'a', 'Gemini', 'woman', 'have', 'a', 'successful', 'relationship', '?', 'Or', 'are', 'they', 'incompatible', '?']),\n",
       "       list(['How', 'can', 'I', 'delete', 'my', 'own', 'question', 'from', 'Quora', '?']),\n",
       "       list(['Why', 'are', 'there', 'still', 'people', 'who', 'think', 'that', 'the', 'Earth', 'is', 'flat', '?']),\n",
       "       ...,\n",
       "       list(['Which', 'mobile', 'phone', 'should', 'I', 'buy', 'under', 'Rs.15000', '?']),\n",
       "       list(['Should', 'I', 'invest', 'in', 'Bitcoin', 'now', '?', 'Why', '?']),\n",
       "       list(['Has', 'anyone', 'been', 'able', 'to', 'stop', 'masturbating', '?', 'If', 'yes', ',', 'how', '?'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "850781a0-c9f0-4914-921d-7943a42c23a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'<PAD>': 1,\n",
       "             'Can': 2,\n",
       "             'a': 3,\n",
       "             'Gemini': 4,\n",
       "             'man': 5,\n",
       "             'and': 6,\n",
       "             'woman': 7,\n",
       "             'have': 8,\n",
       "             'successful': 9,\n",
       "             'relationship': 10,\n",
       "             '?': 11,\n",
       "             'Or': 12,\n",
       "             'are': 13,\n",
       "             'they': 14,\n",
       "             'incompatible': 15,\n",
       "             'What': 16,\n",
       "             'is': 17,\n",
       "             'the': 18,\n",
       "             'compatibility': 19,\n",
       "             'of': 20,\n",
       "             ',': 21,\n",
       "             'romantically': 22,\n",
       "             'How': 23,\n",
       "             'can': 24,\n",
       "             'I': 25,\n",
       "             'delete': 26,\n",
       "             'my': 27,\n",
       "             'own': 28,\n",
       "             'question': 29,\n",
       "             'from': 30,\n",
       "             'Quora': 31,\n",
       "             'all': 32,\n",
       "             'questions': 33,\n",
       "             'asked': 34,\n",
       "             'on': 35,\n",
       "             'Why': 36,\n",
       "             'there': 37,\n",
       "             'still': 38,\n",
       "             'people': 39,\n",
       "             'who': 40,\n",
       "             'think': 41,\n",
       "             'that': 42,\n",
       "             'Earth': 43,\n",
       "             'flat': 44,\n",
       "             'do': 45,\n",
       "             'some': 46,\n",
       "             'currently': 47,\n",
       "             'believe': 48,\n",
       "             'earth': 49,\n",
       "             'should': 50,\n",
       "             'to': 51,\n",
       "             'concentrate': 52,\n",
       "             'more': 53,\n",
       "             'studies': 54,\n",
       "             'in': 55,\n",
       "             'study': 56,\n",
       "             'one': 57,\n",
       "             'stop': 58,\n",
       "             'caring': 59,\n",
       "             'too': 60,\n",
       "             'much': 61,\n",
       "             'myself': 62,\n",
       "             'lose': 63,\n",
       "             'fat': 64,\n",
       "             'thighs': 65,\n",
       "             'hips': 66,\n",
       "             'as': 67,\n",
       "             'soon': 68,\n",
       "             'possible': 69,\n",
       "             'female': 70,\n",
       "             'reduce': 71,\n",
       "             'fast': 72,\n",
       "             'forever': 73,\n",
       "             'body': 74,\n",
       "             'weight': 75,\n",
       "             'actually': 76,\n",
       "             'start': 77,\n",
       "             'IAS': 78,\n",
       "             'preparation': 79,\n",
       "             'along': 80,\n",
       "             'with': 81,\n",
       "             'BE': 82,\n",
       "             'engineering': 83,\n",
       "             'for': 84,\n",
       "             'your': 85,\n",
       "             'favourite': 86,\n",
       "             'books': 87,\n",
       "             'book': 88,\n",
       "             'weirdest': 89,\n",
       "             'thing': 90,\n",
       "             'you': 91,\n",
       "             'found': 92,\n",
       "             'internet': 93,\n",
       "             'things': 94,\n",
       "             \"'ve\": 95,\n",
       "             'read': 96,\n",
       "             'will': 97,\n",
       "             'if': 98,\n",
       "             'become': 99,\n",
       "             'invisible': 100,\n",
       "             'day': 101,\n",
       "             'get': 102,\n",
       "             'pregnant': 103,\n",
       "             'two': 104,\n",
       "             'days': 105,\n",
       "             'after': 106,\n",
       "             'period': 107,\n",
       "             'ends': 108,\n",
       "             'fall': 109,\n",
       "             '3days': 110,\n",
       "             'over': 111,\n",
       "             'someone': 112,\n",
       "             'loved': 113,\n",
       "             'best': 114,\n",
       "             'way': 115,\n",
       "             'an': 116,\n",
       "             'ex': 117,\n",
       "             'Are': 118,\n",
       "             'indoors': 119,\n",
       "             'thinner': 120,\n",
       "             'air': 121,\n",
       "             'than': 122,\n",
       "             'outdoors': 123,\n",
       "             'Is': 124,\n",
       "             'reason': 125,\n",
       "             'gravitational': 126,\n",
       "             'force': 127,\n",
       "             'behind': 128,\n",
       "             'Gravitational': 129,\n",
       "             'Force': 130,\n",
       "             'it': 131,\n",
       "             'travel': 132,\n",
       "             'through': 133,\n",
       "             'time': 134,\n",
       "             'already': 135,\n",
       "             'movies': 136,\n",
       "             'times': 137,\n",
       "             'watch': 138,\n",
       "             '(': 139,\n",
       "             'animated': 140,\n",
       "             'welcome': 141,\n",
       "             ')': 142,\n",
       "             'till': 143,\n",
       "             'date': 144,\n",
       "             'three': 145,\n",
       "             'everyone': 146,\n",
       "             'ever': 147,\n",
       "             'his/her': 148,\n",
       "             'lifetime': 149,\n",
       "             'difference': 150,\n",
       "             'between': 151,\n",
       "             'unicellular': 152,\n",
       "             'multicellular': 153,\n",
       "             'organism': 154,\n",
       "             'Donald': 155,\n",
       "             'Trump': 156,\n",
       "             'has': 157,\n",
       "             'mental': 158,\n",
       "             'problem': 159,\n",
       "             'Have': 160,\n",
       "             'every': 161,\n",
       "             'been': 162,\n",
       "             'any': 163,\n",
       "             'stability': 164,\n",
       "             'issues': 165,\n",
       "             'life': 166,\n",
       "             'overcome': 167,\n",
       "             'OCD': 168,\n",
       "             'hate': 169,\n",
       "             'most': 170,\n",
       "             'about': 171,\n",
       "             'Facebook': 172,\n",
       "             'did': 173,\n",
       "             'eyes': 174,\n",
       "             'evolve': 175,\n",
       "             'organisms': 176,\n",
       "             'why': 177,\n",
       "             'we': 178,\n",
       "             'capable': 179,\n",
       "             'see': 180,\n",
       "             'light': 181,\n",
       "             'limited': 182,\n",
       "             'wavelengths': 183,\n",
       "             '400-700': 184,\n",
       "             'only': 185,\n",
       "             'first': 186,\n",
       "             'eye': 187,\n",
       "             'creature': 188,\n",
       "             'evolved': 189,\n",
       "             'lights': 190,\n",
       "             '400-700nm': 191,\n",
       "             'just': 192,\n",
       "             'started': 193,\n",
       "             \"'s\": 194,\n",
       "             'brown': 195,\n",
       "             'this': 196,\n",
       "             'normal': 197,\n",
       "             'discharge': 198,\n",
       "             'during': 199,\n",
       "             'Which': 200,\n",
       "             'love': 201,\n",
       "             'story': 202,\n",
       "             'novels': 203,\n",
       "             'unusual': 204,\n",
       "             'dream': 205,\n",
       "             'had': 206,\n",
       "             'was': 207,\n",
       "             'know': 208,\n",
       "             'wife': 209,\n",
       "             'cheater': 210,\n",
       "             'spouse': 211,\n",
       "             'cheating': 212,\n",
       "             'songs': 213,\n",
       "             'listen': 214,\n",
       "             'when': 215,\n",
       "             'presidential': 216,\n",
       "             'parliamentary': 217,\n",
       "             'government': 218,\n",
       "             'systems': 219,\n",
       "             'different': 220,\n",
       "             'similar': 221,\n",
       "             'what': 222,\n",
       "             'understand': 223,\n",
       "             'each': 224,\n",
       "             'other': 225,\n",
       "             'Where': 226,\n",
       "             'specifically': 227,\n",
       "             'tsunamis': 228,\n",
       "             'happen': 229,\n",
       "             'usually': 230,\n",
       "             'take': 231,\n",
       "             'place': 232,\n",
       "             'major': 233,\n",
       "             'differences': 234,\n",
       "             'Chinese': 235,\n",
       "             'Western': 236,\n",
       "             'cultures': 237,\n",
       "             'biggest': 238,\n",
       "             'online': 239,\n",
       "             'courses': 240,\n",
       "             'available': 241,\n",
       "             'digital': 242,\n",
       "             'business': 243,\n",
       "             'marketing': 244,\n",
       "             'management': 245,\n",
       "             'top': 246,\n",
       "             'want': 247,\n",
       "             'work': 248,\n",
       "             'does': 249,\n",
       "             'rain': 250,\n",
       "             'so': 251,\n",
       "             'Bogota': 252,\n",
       "             'Colombia': 253,\n",
       "             'writer': 254,\n",
       "             'block': 255,\n",
       "             'opinion': 256,\n",
       "             'crippling': 257,\n",
       "             'If': 258,\n",
       "             'leave': 259,\n",
       "             'university': 260,\n",
       "             'admission': 261,\n",
       "             'another': 262,\n",
       "             'new': 263,\n",
       "             'previous': 264,\n",
       "             'institute': 265,\n",
       "             'anyone': 266,\n",
       "             'views': 267,\n",
       "             'persons': 268,\n",
       "             'visited': 269,\n",
       "             'profile': 270,\n",
       "             'hurt': 271,\n",
       "             'Will': 272,\n",
       "             'ww3': 273,\n",
       "             'be': 274,\n",
       "             'WW3': 275,\n",
       "             'or': 276,\n",
       "             'not': 277,\n",
       "             'makes': 278,\n",
       "             'India': 279,\n",
       "             'countries': 280,\n",
       "             'world': 281,\n",
       "             'separate': 282,\n",
       "             'making': 283,\n",
       "             'unique': 284,\n",
       "             'special': 285,\n",
       "             'teach': 286,\n",
       "             'child': 287,\n",
       "             'handle': 288,\n",
       "             'bullies': 289,\n",
       "             'bullying': 290,\n",
       "             'use': 291,\n",
       "             'kinetic': 292,\n",
       "             'energy': 293,\n",
       "             'cosmic': 294,\n",
       "             'rays': 295,\n",
       "             'resource': 296,\n",
       "             'converted': 297,\n",
       "             'usable': 298,\n",
       "             'electricity': 299,\n",
       "             'bachelors': 300,\n",
       "             'physics': 301,\n",
       "             'scope': 302,\n",
       "             'bsc': 303,\n",
       "             'English': 304,\n",
       "             'language': 305,\n",
       "             'important': 306,\n",
       "             'learn': 307,\n",
       "             'Who': 308,\n",
       "             'Aristotle': 309,\n",
       "             'were': 310,\n",
       "             'his': 311,\n",
       "             'teachings': 312,\n",
       "             'beliefs': 313,\n",
       "             'game': 314,\n",
       "             '2016': 315,\n",
       "             'games': 316,\n",
       "             'political': 317,\n",
       "             'structure': 318,\n",
       "             'Kiev': 319,\n",
       "             'Russia': 320,\n",
       "             'like': 321,\n",
       "             'Kievan': 322,\n",
       "             'Rus': 323,\n",
       "             'Prime': 324,\n",
       "             'Minister': 325,\n",
       "             'Do': 326,\n",
       "             'Indians': 327,\n",
       "             'widest': 328,\n",
       "             'variety': 329,\n",
       "             'food': 330,\n",
       "             'their': 331,\n",
       "             'cuisine': 332,\n",
       "             'Does': 333,\n",
       "             'its': 334,\n",
       "             'seen': 335,\n",
       "             'UFO': 336,\n",
       "             'alien': 337,\n",
       "             'meaning': 338,\n",
       "             'purpose': 339,\n",
       "             'mathematically': 340,\n",
       "             'logically': 341,\n",
       "             'Jio': 342,\n",
       "             '3G': 343,\n",
       "             'phone': 344,\n",
       "             'human': 345,\n",
       "             'right': 346,\n",
       "             'humanity': 347,\n",
       "             'rights': 348,\n",
       "             'going': 349,\n",
       "             'president': 350,\n",
       "             'chance': 351,\n",
       "             'winning': 352,\n",
       "             'forthcoming': 353,\n",
       "             'election': 354,\n",
       "             'inspired': 355,\n",
       "             'inspires': 356,\n",
       "             'liquid': 357,\n",
       "             'substance': 358,\n",
       "             'heating': 359,\n",
       "             'convert': 360,\n",
       "             'into': 361,\n",
       "             'solid': 362,\n",
       "             'which': 363,\n",
       "             'heated': 364,\n",
       "             'changes': 365,\n",
       "             'pretending': 366,\n",
       "             'would': 367,\n",
       "             'rather': 368,\n",
       "             \"n't\": 369,\n",
       "             'realistic/true': 370,\n",
       "             'movie': 371,\n",
       "             'Black': 372,\n",
       "             'Hawk': 373,\n",
       "             'Down': 374,\n",
       "             'black': 375,\n",
       "             'hawk': 376,\n",
       "             'down': 377,\n",
       "             'real': 378,\n",
       "             'rid': 379,\n",
       "             'Erectile': 380,\n",
       "             'Dysfunction': 381,\n",
       "             'resolve': 382,\n",
       "             'erectile': 383,\n",
       "             'dysfunction': 384,\n",
       "             'ways': 385,\n",
       "             'addiction': 386,\n",
       "             'out': 387,\n",
       "             'whether': 388,\n",
       "             'bootloader': 389,\n",
       "             'unlocked': 390,\n",
       "             'check': 391,\n",
       "             'cure': 392,\n",
       "             'hormonal': 393,\n",
       "             'acne': 394,\n",
       "             'treatment': 395,\n",
       "             '``': 396,\n",
       "             'Life': 397,\n",
       "             \"''\": 398,\n",
       "             'earn': 399,\n",
       "             'money': 400,\n",
       "             'easily': 401,\n",
       "             'make': 402,\n",
       "             'consistently': 403,\n",
       "             'subsistence': 404,\n",
       "             'agriculture': 405,\n",
       "             'modern': 406,\n",
       "             'commercial': 407,\n",
       "             'girlfriend': 408,\n",
       "             'affair': 409,\n",
       "             'Related': 410,\n",
       "             'technology': 411,\n",
       "             'problems': 412,\n",
       "             'solved': 413,\n",
       "             'yet': 414,\n",
       "             'better': 415,\n",
       "             'Hillary': 416,\n",
       "             'Clinton': 417,\n",
       "             'breakfast': 418,\n",
       "             'girl': 419,\n",
       "             'ok': 420,\n",
       "             'eat': 421,\n",
       "             'trying': 422,\n",
       "             'hilarious': 423,\n",
       "             'sarcastic': 424,\n",
       "             'answers': 425,\n",
       "             'answer': 426,\n",
       "             'hijab': 427,\n",
       "             'guys': 428,\n",
       "             'Hijabs': 429,\n",
       "             'meme': 430,\n",
       "             'created': 431,\n",
       "             'find': 432,\n",
       "             'guy': 433,\n",
       "             'girls': 434,\n",
       "             'hard': 435,\n",
       "             'parent': 436,\n",
       "             'really': 437,\n",
       "             'Batman': 438,\n",
       "             'lift': 439,\n",
       "             'Mjölnir': 440,\n",
       "             'Thor': 441,\n",
       "             'hammer': 442,\n",
       "             'forget': 443,\n",
       "             'whom': 444,\n",
       "             'heart': 445,\n",
       "             'salaries': 446,\n",
       "             'chemical': 447,\n",
       "             'engineers': 448,\n",
       "             'salary': 449,\n",
       "             'prons': 450,\n",
       "             'cons': 451,\n",
       "             'banning': 452,\n",
       "             'replacing': 453,\n",
       "             '₹500': 454,\n",
       "             '₹1000': 455,\n",
       "             'Notes': 456,\n",
       "             'pros': 457,\n",
       "             '500': 458,\n",
       "             '1000': 459,\n",
       "             'rupee': 460,\n",
       "             'notes': 461,\n",
       "             'arguments': 462,\n",
       "             'war': 463,\n",
       "             'drugs': 464,\n",
       "             'ending': 465,\n",
       "             'follow': 466,\n",
       "             'Instagram': 467,\n",
       "             'how': 468,\n",
       "             'many': 469,\n",
       "             'viewed': 470,\n",
       "             'stories': 471,\n",
       "             'under': 472,\n",
       "             '50000': 473,\n",
       "             'rupees': 474,\n",
       "             'INR': 475,\n",
       "             'rs': 476,\n",
       "             'die': 477,\n",
       "             'change': 478,\n",
       "             'improve': 479,\n",
       "             'yourself': 480,\n",
       "             'aspects': 481,\n",
       "             'well？': 482,\n",
       "             'procrastinating': 483,\n",
       "             'COMPLETELY': 484,\n",
       "             'being': 485,\n",
       "             'procrastinator': 486,\n",
       "             'inspirational': 487,\n",
       "             'writers': 488,\n",
       "             'inspiring': 489,\n",
       "             'second': 490,\n",
       "             'hand': 491,\n",
       "             'high': 492,\n",
       "             'vaping': 493,\n",
       "             'weed': 494,\n",
       "             'off': 495,\n",
       "             'smoking': 496,\n",
       "             'next': 497,\n",
       "             'car': 498,\n",
       "             'dislike': 499,\n",
       "             'she': 500,\n",
       "             'done': 501,\n",
       "             'wrong': 502,\n",
       "             'Hilary': 503,\n",
       "             'embarrassing': 504,\n",
       "             'happened': 505,\n",
       "             'school': 506,\n",
       "             'survive': 507,\n",
       "             '.50': 508,\n",
       "             'AE': 509,\n",
       "             'Desert': 510,\n",
       "             'Eagle': 511,\n",
       "             'shot': 512,\n",
       "             'shoot': 513,\n",
       "             'me': 514,\n",
       "             '50AE': 515,\n",
       "             '300grain': 516,\n",
       "             'HP': 517,\n",
       "             '!': 518,\n",
       "             'Precent': 519,\n",
       "             'serieusly': 520,\n",
       "             'irrespective': 521,\n",
       "             'genre': 522,\n",
       "             'met': 523,\n",
       "             'Has': 524,\n",
       "             'according': 525,\n",
       "             'betting': 526,\n",
       "             'horses': 527,\n",
       "             'per': 528,\n",
       "             'month': 529,\n",
       "             'A': 530,\n",
       "             '20,000': 531,\n",
       "             'log': 532,\n",
       "             'forgot': 533,\n",
       "             'password': 534,\n",
       "             'old': 535,\n",
       "             'account': 536,\n",
       "             'entire': 537,\n",
       "             'brain': 538,\n",
       "             'pick': 539,\n",
       "             'up': 540,\n",
       "             'neural': 541,\n",
       "             'activity': 542,\n",
       "             'by': 543,\n",
       "             'means': 544,\n",
       "             'reading': 545,\n",
       "             'EM': 546,\n",
       "             'field': 547,\n",
       "             'caused': 548,\n",
       "             'localized': 549,\n",
       "             'intercepts': 550,\n",
       "             'simultaneously': 551,\n",
       "             'activities': 552,\n",
       "             'advantage': 553,\n",
       "             'speaking': 554,\n",
       "             'feed': 555,\n",
       "             'puppy': 556,\n",
       "             'foods': 557,\n",
       "             'dogs': 558,\n",
       "             'without': 559,\n",
       "             'investment': 560,\n",
       "             'kind': 561,\n",
       "             'impact': 562,\n",
       "             'becomes': 563,\n",
       "             'USA': 564,\n",
       "             'affects': 565,\n",
       "             'completely': 566,\n",
       "             'straight': 567,\n",
       "             'forward': 568,\n",
       "             'marked': 569,\n",
       "             'needing': 570,\n",
       "             'improvement': 571,\n",
       "             'elect': 572,\n",
       "             'getting': 573,\n",
       "             'flagged': 574,\n",
       "             'clear': 575,\n",
       "             'concise': 576,\n",
       "             'causes': 577,\n",
       "             'effects': 578,\n",
       "             'Roman': 579,\n",
       "             'Empire': 580,\n",
       "             'reasons': 581,\n",
       "             'collapse': 582,\n",
       "             'land': 583,\n",
       "             'sea': 584,\n",
       "             'breezes': 585,\n",
       "             'blow': 586,\n",
       "             'toward': 587,\n",
       "             'aliens': 588,\n",
       "             'exist': 589,\n",
       "             'governments': 590,\n",
       "             'hide': 591,\n",
       "             'ban': 592,\n",
       "             'affect': 593,\n",
       "             'Indian': 594,\n",
       "             'economy': 595,\n",
       "             'introducing': 596,\n",
       "             '2000': 597,\n",
       "             'When': 598,\n",
       "             'Sword': 599,\n",
       "             'Art': 600,\n",
       "             'Online': 601,\n",
       "             'season': 602,\n",
       "             '3': 603,\n",
       "             'come': 604,\n",
       "             'MBA': 605,\n",
       "             'BA': 606,\n",
       "             'travelling': 607,\n",
       "             'at': 608,\n",
       "             'least': 609,\n",
       "             'shifted': 610,\n",
       "             'vision': 611,\n",
       "             'finally': 612,\n",
       "             'could': 613,\n",
       "             'masturbating': 614,\n",
       "             'urge': 615,\n",
       "             'masturbate': 616,\n",
       "             'Short': 617,\n",
       "             'Motivation': 618,\n",
       "             'Quotes': 619,\n",
       "             'short': 620,\n",
       "             'motivational': 621,\n",
       "             'quotes': 622,\n",
       "             'SpaceX': 623,\n",
       "             '2014': 624,\n",
       "             'billion': 625,\n",
       "             'dollars': 626,\n",
       "             'sexual': 627,\n",
       "             'impotence': 628,\n",
       "             'medicine': 629,\n",
       "             'treat': 630,\n",
       "             'microeconomics': 631,\n",
       "             'macroeconomics': 632,\n",
       "             'relate': 633,\n",
       "             'favorite': 634,\n",
       "             'colors': 635,\n",
       "             'color': 636,\n",
       "             'And': 637,\n",
       "             'switch': 638,\n",
       "             'isotope': 639,\n",
       "             'isotopes': 640,\n",
       "             'i': 641,\n",
       "             'messages': 642,\n",
       "             'On': 643,\n",
       "             'inbox': 644,\n",
       "             'non-Muslim': 645,\n",
       "             'men': 646,\n",
       "             'marrying': 647,\n",
       "             'Muslim': 648,\n",
       "             'women': 649,\n",
       "             'then': 650,\n",
       "             'converting': 651,\n",
       "             'Islam': 652,\n",
       "             'non': 653,\n",
       "             'Men': 654,\n",
       "             'considering': 655,\n",
       "             'present': 656,\n",
       "             'scenario': 657,\n",
       "             'around': 658,\n",
       "             'us': 659,\n",
       "             '.': 660,\n",
       "             'characteristics': 661,\n",
       "             'Italian': 662,\n",
       "             'leather': 663,\n",
       "             'distinguish': 664,\n",
       "             'itself': 665,\n",
       "             'types': 666,\n",
       "             'diet': 667,\n",
       "             'veg': 668,\n",
       "             'non-veg': 669,\n",
       "             'Veg': 670,\n",
       "             'safety': 671,\n",
       "             'precautions': 672,\n",
       "             'handling': 673,\n",
       "             'shotguns': 674,\n",
       "             'proposed': 675,\n",
       "             'NRA': 676,\n",
       "             'Montana': 677,\n",
       "             'Pennsylvania': 678,\n",
       "             'role': 679,\n",
       "             'stock': 680,\n",
       "             'exchange': 681,\n",
       "             'examples': 682,\n",
       "             'roles': 683,\n",
       "             'deal': 684,\n",
       "             'depression': 685,\n",
       "             'siginficance': 686,\n",
       "             'merging': 687,\n",
       "             'railway': 688,\n",
       "             'budget': 689,\n",
       "             'general': 690,\n",
       "             'merges': 691,\n",
       "             'Should': 692,\n",
       "             'control': 693,\n",
       "             'masturbation': 694,\n",
       "             'disable': 695,\n",
       "             'comments': 696,\n",
       "             'simply': 697,\n",
       "             'look': 698,\n",
       "             'comment': 699,\n",
       "             'section': 700,\n",
       "             'hack': 701,\n",
       "             'husband': 702,\n",
       "             'device': 703,\n",
       "             'wo': 704,\n",
       "             'iPod': 705,\n",
       "             'Touch': 706,\n",
       "             '4th': 707,\n",
       "             'Generation': 708,\n",
       "             'charge': 709,\n",
       "             'touch': 710,\n",
       "             'turning': 711,\n",
       "             'charging': 712,\n",
       "             'news': 713,\n",
       "             'channel': 714,\n",
       "             'channels': 715,\n",
       "             'strategically': 716,\n",
       "             'Agent': 717,\n",
       "             'Orange': 718,\n",
       "             'used': 719,\n",
       "             'Vietnam': 720,\n",
       "             'War': 721,\n",
       "             'mentally': 722,\n",
       "             'stronger': 723,\n",
       "             'emotionally': 724,\n",
       "             'strong': 725,\n",
       "             'programming': 726,\n",
       "             'resources': 727,\n",
       "             'web': 728,\n",
       "             'websites': 729,\n",
       "             'computer': 730,\n",
       "             'mean': 731,\n",
       "             'hypocrite': 732,\n",
       "             'usual': 733,\n",
       "             'learning': 734,\n",
       "             'Machine': 735,\n",
       "             'Learning': 736,\n",
       "             'determine': 737,\n",
       "             'atomic': 738,\n",
       "             'radius': 739,\n",
       "             'niobium': 740,\n",
       "             'determined': 741,\n",
       "             'ideas': 742,\n",
       "             'early': 743,\n",
       "             'morning': 744,\n",
       "             'wake': 745,\n",
       "             'recreational': 746,\n",
       "             'likely': 747,\n",
       "             'made': 748,\n",
       "             'legal': 749,\n",
       "             'Australia': 750,\n",
       "             'anytime': 751,\n",
       "             'recreation': 752,\n",
       "             'chest': 753,\n",
       "             'tips': 754,\n",
       "             'prepare': 755,\n",
       "             'case': 756,\n",
       "             'interviews': 757,\n",
       "             'Business': 758,\n",
       "             'Analytics': 759,\n",
       "             'position': 760,\n",
       "             'ZS': 761,\n",
       "             'Associates': 762,\n",
       "             'am': 763,\n",
       "             'having': 764,\n",
       "             'interview': 765,\n",
       "             'analytics': 766,\n",
       "             'associate': 767,\n",
       "             'let': 768,\n",
       "             'upvote': 769,\n",
       "             'good': 770,\n",
       "             'allow': 771,\n",
       "             'steps': 772,\n",
       "             'writing': 773,\n",
       "             'skills': 774,\n",
       "             'track': 775,\n",
       "             'lost': 776,\n",
       "             'iPhone': 777,\n",
       "             '4s': 778,\n",
       "             'using': 779,\n",
       "             'imei': 780,\n",
       "             'code': 781,\n",
       "             'mobile': 782,\n",
       "             'IMEI': 783,\n",
       "             'sound': 784,\n",
       "             'helps': 785,\n",
       "             'asleep': 786,\n",
       "             'music': 787,\n",
       "             'help': 788,\n",
       "             'perceptual': 789,\n",
       "             'saliency': 790,\n",
       "             'salience': 791,\n",
       "             'Kinder': 792,\n",
       "             'Surprise': 793,\n",
       "             'eggs': 794,\n",
       "             'illegal': 795,\n",
       "             'banned': 796,\n",
       "             'United': 797,\n",
       "             'States': 798,\n",
       "             'head': 799,\n",
       "             'college': 800,\n",
       "             'besides': 801,\n",
       "             'taking': 802,\n",
       "             'AP': 803,\n",
       "             'classes': 804,\n",
       "             'clep': 805,\n",
       "             'aside': 806,\n",
       "             'CLEP': 807,\n",
       "             'Python': 808,\n",
       "             'Socket': 809,\n",
       "             'Programming': 810,\n",
       "             'modules': 811,\n",
       "             'decide': 812,\n",
       "             'order': 813,\n",
       "             'determines': 814,\n",
       "             'July': 815,\n",
       "             '1': 816,\n",
       "             'journalist': 817,\n",
       "             'upvoted': 818,\n",
       "             'them': 819,\n",
       "             'care': 820,\n",
       "             'nation': 821,\n",
       "             'bicycle': 822,\n",
       "             'commute': 823,\n",
       "             'office': 824,\n",
       "             'within': 825,\n",
       "             '15k': 826,\n",
       "             'buy': 827,\n",
       "             'range': 828,\n",
       "             '10k': 829,\n",
       "             'Best': 830,\n",
       "             'stay': 831,\n",
       "             'Goa': 832,\n",
       "             'hotels': 833,\n",
       "             'transplant': 834,\n",
       "             'true': 835,\n",
       "             'transplanted': 836,\n",
       "             'potty': 837,\n",
       "             'train': 838,\n",
       "             '4': 839,\n",
       "             'our': 840,\n",
       "             'currency': 841,\n",
       "             'note': 842,\n",
       "             'Rs.2000': 843,\n",
       "             'equipped': 844,\n",
       "             'nano': 845,\n",
       "             'GPS': 846,\n",
       "             'chips': 847,\n",
       "             'American': 848,\n",
       "             'schools': 849,\n",
       "             'distribute': 850,\n",
       "             'birth': 851,\n",
       "             'students': 852,\n",
       "             'yes': 853,\n",
       "             'parents': 854,\n",
       "             'notified': 855,\n",
       "             'Sahara': 856,\n",
       "             'average': 857,\n",
       "             'temperatures': 858,\n",
       "             'compare': 859,\n",
       "             'ones': 860,\n",
       "             'Atacama': 861,\n",
       "             'Mojave': 862,\n",
       "             'approach': 863,\n",
       "             'sponsors': 864,\n",
       "             'events': 865,\n",
       "             'national': 866,\n",
       "             'level': 867,\n",
       "             'event': 868,\n",
       "             'yo': 869,\n",
       "             'avoid': 870,\n",
       "             'paying': 871,\n",
       "             'taxes': 872,\n",
       "             'income': 873,\n",
       "             'tax': 874,\n",
       "             '30': 875,\n",
       "             'pounds': 876,\n",
       "             'olive': 877,\n",
       "             'oil': 878,\n",
       "             'moisturizer': 879,\n",
       "             'face': 880,\n",
       "             'put': 881,\n",
       "             'programmer': 882,\n",
       "             'year': 883,\n",
       "             'very': 884,\n",
       "             'message': 885,\n",
       "             'personal': 886,\n",
       "             'win': 887,\n",
       "             'terrorism': 888,\n",
       "             'terror': 889,\n",
       "             'won': 890,\n",
       "             'unnecessarily': 891,\n",
       "             'edit': 892,\n",
       "             'full': 893,\n",
       "             'freedom': 894,\n",
       "             'speech': 895,\n",
       "             'Internet': 896,\n",
       "             'no': 897,\n",
       "             'gay': 898,\n",
       "             'family': 899,\n",
       "             'Were': 900,\n",
       "             'original': 901,\n",
       "             'Arabs': 902,\n",
       "             'Arabia': 903,\n",
       "             'Black-African': 904,\n",
       "             'Original': 905,\n",
       "             'Arabian': 906,\n",
       "             'Peninsula': 907,\n",
       "             'al': 908,\n",
       "             'reset': 909,\n",
       "             'Gmail': 910,\n",
       "             'forgotten': 911,\n",
       "             'details': 912,\n",
       "             'art': 913,\n",
       "             'arts': 914,\n",
       "             'option': 915,\n",
       "             'workout': 916,\n",
       "             ':': 917,\n",
       "             'cold': 918,\n",
       "             'water': 919,\n",
       "             'shower': 920,\n",
       "             'hot': 921,\n",
       "             'warm': 922,\n",
       "             'gym': 923,\n",
       "             'America': 924,\n",
       "             'Americans': 925,\n",
       "             '8': 926,\n",
       "             'week': 927,\n",
       "             'Husky': 928,\n",
       "             'biting': 929,\n",
       "             'shoes': 930,\n",
       "             'German': 931,\n",
       "             'Shepherd/Border': 932,\n",
       "             'Collie': 933,\n",
       "             'mix': 934,\n",
       "             'chewing': 935,\n",
       "             'reviews': 936,\n",
       "             'Food': 937,\n",
       "             'Grade': 938,\n",
       "             'Diatomaceous': 939,\n",
       "             'grade': 940,\n",
       "             'diatomaceous': 941,\n",
       "             'safe': 942,\n",
       "             'animal': 943,\n",
       "             'loyal': 944,\n",
       "             'humans': 945,\n",
       "             'pet': 946,\n",
       "             'salicylic': 947,\n",
       "             'acid': 948,\n",
       "             'benzoyl': 949,\n",
       "             'peroxide': 950,\n",
       "             'prevent': 951,\n",
       "             'cystic': 952,\n",
       "             'New': 953,\n",
       "             'Year': 954,\n",
       "             'Resolution': 955,\n",
       "             'Years': 956,\n",
       "             'grades': 957,\n",
       "             'class': 958,\n",
       "             'Quorans': 959,\n",
       "             'Quoran': 960,\n",
       "             'software': 961,\n",
       "             'download': 962,\n",
       "             'YouTube': 963,\n",
       "             'playlist': 964,\n",
       "             'Windows': 965,\n",
       "             'eating': 966,\n",
       "             'rice': 967,\n",
       "             'sleepy': 968,\n",
       "             'awhile': 969,\n",
       "             'feel': 970,\n",
       "             'drowsy': 971,\n",
       "             'expected': 972,\n",
       "             'cut': 973,\n",
       "             'SSC': 974,\n",
       "             'CGL': 975,\n",
       "             'Tier': 976,\n",
       "             'rise': 977,\n",
       "             'paper': 978,\n",
       "             'easy': 979,\n",
       "             'vacancies': 980,\n",
       "             'less': 981,\n",
       "             'write': 982,\n",
       "             'beautiful': 983,\n",
       "             'introduction': 984,\n",
       "             'essay': 985,\n",
       "             'pass': 986,\n",
       "             'job': 987,\n",
       "             'successfully': 988,\n",
       "             'dente': 989,\n",
       "             'parallel': 990,\n",
       "             'universe': 991,\n",
       "             'universes': 992,\n",
       "             'locate': 993,\n",
       "             'someones': 994,\n",
       "             'knowing': 995,\n",
       "             'apps': 996,\n",
       "             'location': 997,\n",
       "             'him': 998,\n",
       "             'student': 999,\n",
       "             'Electrical': 1000,\n",
       "             ...})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2048ec8b-b5fd-4295-a4ba-5c9ab5e825ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(q1_train)):\n",
    "    q1_train[i] = [vocab[word] for word in q1_train[i]]\n",
    "    q2_train[i] = [vocab[word] for word in q2_train[i]]\n",
    "\n",
    "        \n",
    "for i in range(len(q1_test)):\n",
    "    q1_test[i] = [vocab[word] for word in q1_test[i]]\n",
    "    q2_test[i] = [vocab[word] for word in q2_test[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c4755de-ca53-4cf0-85b3-80aeea5b4cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([16, 17, 18, 19, 20, 3, 4, 5, 6, 3, 4, 7, 21, 22, 11]),\n",
       "       list([2, 25, 26, 32, 18, 33, 25, 34, 35, 31, 11]),\n",
       "       list([36, 45, 46, 39, 47, 48, 18, 49, 17, 44, 11]), ...,\n",
       "       list([200, 13, 114, 782, 1131, 51, 827, 472, 1292, 11]),\n",
       "       list([692, 25, 4191, 55, 3922, 11]),\n",
       "       list([23, 24, 25, 58, 614, 11])], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd48f5c9-a48e-41c2-97e8-a975e6ae8b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train, q1_val, q2_train, q2_val = train_test_split(q1_train, q2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8eb3eb9-c3eb-4bbb-b3c1-0a9c2fecc898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest(lst):\n",
    "    \"\"\"\n",
    "    Returns len of longest list in array\n",
    "    \"\"\"\n",
    "    longest_list = max(len(elem) for elem in lst)\n",
    "    return longest_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1ce8267b-c086-47ad-baf2-33ea0c676e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supplement(array, length, pad):\n",
    "    \"\"\"\n",
    "    Add pad elements to complete array to needed len\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in range(len(array)):\n",
    "        result.append(np.hstack((array[i], [pad]*(length-len(array[i])))))\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1d32a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  23,   24,   25,  180,   40,  470,   27, 1442,   11,    1,   23,\n",
       "         344,   34,   34,  364,    6,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1],\n",
       "       [  23,   17, 7793, 7794,   67,    3, 1677,   11,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1],\n",
       "       [  16,   13,   18,  114, 1182,   91,    8, 4855,   35,  963,   11,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[23, 24, 25, 180, 40, 470, 27, 1442, 11, 1, 23, 344, 34, 34, 364, 6],\n",
    "     [23, 17, 7793, 7794, 67, 3, 1677, 11],\n",
    "     [16, 13, 18, 114, 1182, 91, 8, 4855, 35, 963, 11]\n",
    "     ]\n",
    "supplement(a, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "ab691a5e-8b14-4fb3-aec6-f0f3df70e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, q1, q2):\n",
    "        self.q1 = q1\n",
    "        self.q2 = q2\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = (self.q1[idx], self.q2[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.q1)\n",
    "\n",
    "def iterator(q1, q2, batch_size=128, shuffle=False):\n",
    "    q1, q2 = data_generator(q1, q2, batch_size, shuffle=shuffle) # padding the sequences to the maximum length amongst the samples in batches\n",
    "    dataset = PairsDataset(q1, q2)\n",
    "    return dataset\n",
    "\n",
    "def data_generator(q1, q2, batch_size, pad=1, shuffle=True):\n",
    "    \"\"\"Generator function that yields batches of data\n",
    "\n",
    "    Args:\n",
    "        q1 (list): List of transformed (to tensor) questions.\n",
    "        q2 (list): List of transformed (to tensor) questions.\n",
    "        batch_size (int): Number of elements per batch.\n",
    "        pad (int, optional): Pad character defaults to 1.\n",
    "        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n",
    "    Returns:\n",
    "        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n",
    "        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n",
    "              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n",
    "    \"\"\"\n",
    "    q1_batch_all = []\n",
    "    q2_batch_all = []\n",
    "    idx = 0\n",
    "    len_q = len(q1)\n",
    "    question_indexes = [*range(len_q)]\n",
    "    if shuffle:\n",
    "        random.shuffle(question_indexes) \n",
    "    \n",
    "    q1 = q1[question_indexes]\n",
    "    q2 = q2[question_indexes]\n",
    "\n",
    "    batches_num = ceil(len_q / batch_size)\n",
    "    q1_batch_all = [q1[(i*batch_size):((i+1)*batch_size)] for i in range(batches_num)]\n",
    "    q2_batch_all = [q2[(i*batch_size):((i+1)*batch_size)] for i in range(batches_num)]\n",
    "    \n",
    "    for i in range(batches_num):\n",
    "        max_len = max(longest(q1_batch_all[i]),longest(q2_batch_all[i]))\n",
    "        max_len = 2**int(np.ceil(np.log2(max_len)))\n",
    "\n",
    "        q1_batch_all[i] = supplement(q1_batch_all[i], max_len, pad)\n",
    "        q2_batch_all[i] = supplement(q2_batch_all[i], max_len, pad)\n",
    "        \n",
    "        q1_batch_all[i] = np.array(q1_batch_all[i])\n",
    "        q2_batch_all[i] = np.array(q2_batch_all[i])\n",
    "    return (q1_batch_all, q2_batch_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0fa711-e4d1-4376-b5c2-ca64e091da93",
   "metadata": {},
   "source": [
    "# [7 points] **Part 2: Buiding the siamese network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adc75b73-faa9-4980-817a-603fd826f65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(nn.Module):\n",
    "    \"\"\" Siamese model.\n",
    "\n",
    "    Args:\n",
    "        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n",
    "        d_model (int, optional): Depth of the model. Defaults to 128.\n",
    "        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n",
    "\n",
    "    Returns:\n",
    "        A PyTorch Siamese model. \n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size=len(vocab), d_model=128, hid_size=256, num_layers=2):\n",
    "        super(SiameseModel, self).__init__()\n",
    "        self.emb =  nn.Embedding(vocab_size, d_model) # defining the embeddings of vocab and d_model size\n",
    "        self.lstm = nn.LSTM(d_model, hidden_size=hid_size, num_layers=num_layers, batch_first=True) # Defining an LSTM layer\n",
    "        self.ll = nn.Linear(in_features=128, out_features=2) # Using dense layer \n",
    "\n",
    "    def forward_once(self, q):\n",
    "        # make all the transformations with input \n",
    "        x, _ = self.lstm(self.emb(q))\n",
    "        x = torch.mean(x, dim=1) # get the mean accros 1 axis\n",
    "        x = F.relu(x)\n",
    "        x = self.ll(x)\n",
    "        out = F.normalize(x) # normalize the output\n",
    "        return out\n",
    "\n",
    "    def forward(self, q1, q2):\n",
    "        o1 = self.forward_once(q1)\n",
    "        o2 = self.forward_once(q2)\n",
    "        return (o1, o2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d020a6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00ef42a9-f606-4513-a628-e06319cc8252",
   "metadata": {},
   "source": [
    "# [8 points] **Part 3: Measuring the quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "273a61c1-93d9-4e86-8fde-03b66b948b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_by_rows(tensor):\n",
    "    \"\"\"\n",
    "    Returning tensor containing max of each row in matrix.\n",
    "    \"\"\"\n",
    "    tmp = []\n",
    "    for i in range(tensor.shape[0]):\n",
    "        tmp.append(max(tensor[i]))\n",
    "    \n",
    "    return torch.tensor(tmp, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ba143b3a-5eb4-417d-b7ad-b9b961142f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial as sp\n",
    "\n",
    "\n",
    "class TripletLoss(torch.nn.Module):\n",
    "    \"\"\"Custom Loss function.\n",
    "\n",
    "    Args:\n",
    "        v1 (torch.tensor): Array with dimension (batch_size, model_dimension) associated to Q1.\n",
    "        v2 (torch.tensor): Array with dimension (batch_size, model_dimension) associated to Q2.\n",
    "        margin (torch.tensor, optional): Desired margin. Defaults to 0.25.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def forward(self, v1, v2, margin=torch.tensor([0.25], requires_grad=True)):\n",
    "        scores = torch.tensor(1 - sp.distance.cdist(v1.detach().numpy(),\n",
    "                              v2.detach().numpy(), 'cosine'), requires_grad=True)\n",
    "        batch_size = len(scores)  # calculate new batch size\n",
    "        positive = scores.diag()  # the positive `diagonal` entries in `scores` (duplicates)\n",
    "       \n",
    "        negative_without_positive = scores - 2*torch.eye(v1.shape[0], requires_grad=True)\n",
    "        \n",
    "        closest_negative = get_max_by_rows(negative_without_positive)\n",
    "\n",
    "        \n",
    "        negative_zero_on_duplicate = (1.0 - torch.eye(v1.shape[0], requires_grad=True)) * scores\n",
    "\n",
    "        \n",
    "        mean_negative = torch.sum(\n",
    "            negative_zero_on_duplicate, axis=1) / (batch_size-1)\n",
    "\n",
    "        \n",
    "        loss1 = torch.max(torch.tensor([0.0]),\n",
    "                          margin - positive + closest_negative)\n",
    "        \n",
    "        loss2 = torch.max(torch.tensor([0.0]),\n",
    "                          margin - positive + mean_negative)\n",
    "\n",
    "        triplet_loss = torch.mean(torch.add(loss1, loss2))\n",
    "        return triplet_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fc4a5961-c324-4491-8cf3-ec0fa8e18542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss: tensor(0.5000, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "v1 = torch.tensor(np.array([[0.26726124,  0.53452248,  0.80178373],\n",
    "                            [-0.5178918, -0.57543534, -0.63297887]]), requires_grad=True)\n",
    "v2 = torch.tensor(np.array([[0.26726124, 0.53452248, 0.80178373], \n",
    "                            [0.5178918, 0.57543534, 0.63297887]]), requires_grad=True)\n",
    "loss = TripletLoss()\n",
    "res = loss(v1, v2)\n",
    "print(\"Triplet Loss:\", res)  # expecting 0.5\n",
    "res.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffa853",
   "metadata": {},
   "source": [
    "# [7 points] **Part 4: Training the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "84373cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6da66b18-f1c7-4c97-bb08-4faf013ab91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can vary the hyperparams\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "train_iter = iterator(\n",
    "    q1_train,\n",
    "    q2_train,\n",
    "    BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9639472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = TripletLoss()\n",
    "model = SiameseModel()\n",
    "\n",
    "# you can vary the hyperparams\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=0.0)\n",
    "\n",
    "num_epoch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac8214a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98cc4dffd7b64eebae45851e72b9173a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3928fa859314bf28fcf34218bff6292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epoch)):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    for i, data in tqdm(enumerate(train_iter)):\n",
    "        q1, q2 = data\n",
    "        q1 = torch.tensor(q1)\n",
    "        q2 = torch.tensor(q2)\n",
    "        optimizer.zero_grad()\n",
    "        res = loss.forward(q1, q2)\n",
    "        losses.append(res)\n",
    "        res.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    losses = torch.tensor(losses)\n",
    "    print(f\"Epoch {epoch}\\n Current loss {torch.mean(losses)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3d78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b400e4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
