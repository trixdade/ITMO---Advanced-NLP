{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Speb-Q2b71MH"
      },
      "source": [
        "# Attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsnnXleb71MV"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import scipy.special\n",
        "\n",
        "import textwrap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zjwkNOE71MY"
      },
      "outputs": [],
      "source": [
        "def create_tensor(t):\n",
        "    \"\"\"\n",
        "    Function for creating an np.array array from a list of lists\n",
        "\n",
        "      Arguments:\n",
        "        t: list of lists\n",
        "\n",
        "      Returns:\n",
        "        np.ndarray\n",
        "    \"\"\"\n",
        "    return np.array(t)\n",
        "\n",
        "def print_tensor(t, name):\n",
        "    \"\"\"Displaying the size of the tensor and itself\"\"\"\n",
        "    print(f'{name} shape: {t.shape}\\n {t}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkpFw8r471MZ"
      },
      "outputs": [],
      "source": [
        "assert create_tensor([[1, 0, 0], [0, 1, 0]]).shape == (2, 3)\n",
        "assert type(create_tensor([[1, 2, 3], [4, 5, 6]])) == np.ndarray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsZGsbJX71Ma",
        "outputId": "28047060-b5f0-4a04-ce2a-034ac9ab5c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "query shape: (2, 3)\n",
            " [[1 0 0]\n",
            " [0 1 0]]\n",
            "\n",
            "key shape: (2, 3)\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "value shape: (2, 3)\n",
            " [[0 1 0]\n",
            " [1 0 1]]\n",
            "\n",
            "mask shape: (2, 2)\n",
            " [[ 0.e+00  0.e+00]\n",
            " [-1.e+09  0.e+00]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "q = create_tensor([[1, 0, 0], [0, 1, 0]])\n",
        "print_tensor(q, 'query')\n",
        "k = create_tensor([[1, 2, 3], [4, 5, 6]])\n",
        "print_tensor(k, 'key')\n",
        "v = create_tensor([[0, 1, 0], [1, 0, 1]])\n",
        "print_tensor(v, 'value')\n",
        "m = create_tensor([[0, 0], [-1e9, 0]])\n",
        "print_tensor(m, 'mask')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y2jngi071Mc"
      },
      "outputs": [],
      "source": [
        "def dotProdAtt(query, key, value, mask, scale=True):\n",
        "    \"\"\"\n",
        "    Self attention with a scalar product\n",
        "    \"\"\"\n",
        "    \n",
        "    assert query.shape[-1] == key.shape[-1] == value.shape[-1], \"There is a problem with q, k, v - dimentions differ\"\n",
        "    \n",
        "    # We preserve the depth/dimension of the embedding of the query to reduce the scale of the scalar product\n",
        "    if scale: \n",
        "        depth = query.shape[-1]\n",
        "    else:\n",
        "        depth = 1\n",
        "\n",
        "    # Calculate the scaled scalar product of the key on query\n",
        "    \n",
        "    dots = np.matmul(query, key.T) / np.sqrt(depth) \n",
        "    \n",
        "    # Apply mask\n",
        "    if mask is not None:\n",
        "        dots = np.where(mask, dots, np.full_like(dots, -1e9)) \n",
        "    \n",
        "    # Calculate softmax\n",
        "    from scipy.special import logsumexp\n",
        "    logsumexp = logsumexp(dots, axis=-1, keepdims=True) \n",
        "\n",
        "    # Getting sotmax\n",
        "    dots = np.exp(dots - logsumexp)\n",
        "\n",
        "    # Multiply dots by value to get self-awareness  \n",
        "    attention = np.matmul(dots, value)\n",
        "    \n",
        "    return attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrioXt8j71Me"
      },
      "outputs": [],
      "source": [
        "def dotProdSelfAtt(q, k, v, scale=True):\n",
        "    \"\"\" \n",
        "    Masked self-attention\n",
        "    \"\"\"\n",
        "    \n",
        "    # Size of the penultimate dimension of the query\n",
        "    mask_size = q.shape[-2] \n",
        "\n",
        "    # Creating a matrix with units under the main diagonal and 0 above it. Final dimension: (1, mask_size, mask_size)\n",
        "    mask = np.expand_dims(np.tril(np.ones(mask_size)), axis=0)\n",
        "    \n",
        "    assert np.allclose(mask, np.array([[[1., 0.],\n",
        "                                        [1., 1.]]]))\n",
        "    mask = mask.astype(bool)\n",
        "        \n",
        "    return dotProdAtt(q, k, v, mask, scale=scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z47YSsYH71Me"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(dotProdSelfAtt(q, k, v), \n",
        "               np.array([[[0., 1., 0.],[0.84967455, 0.15032545, 0.84967455]]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPkqZE4jIHFB"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPX50227IoNV"
      },
      "source": [
        "## Classification of sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMVc7vRWIr-2"
      },
      "source": [
        "Based on a dataset of movie reviews, we want to determine the user's mood (sentiment) and predict 1 - if positive sentiment and 0 - if negative.\n",
        "\n",
        "In fact, we use two models for this task:\n",
        "- DistilBERT is a lighter version of BERT created by HuggingFace, while showing a final quality close to BERT.\n",
        "- Logistic regression from sklearn for final classification into positive and negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYanLliDIIq1",
        "outputId": "6fa793c5-c192-4882-b5a4-a3fc586adc1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjpIo--kIu1o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2ToiIhVPTDQ"
      },
      "source": [
        "## Loading and preparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dnEMtZHPknx"
      },
      "source": [
        "To speed up processing, we will take only 3000 sentences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0PqJpUMzjLM"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\n",
        "    'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv',\n",
        "    delimiter='\\t',\n",
        "    header=None\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xxXCH76IxwG",
        "outputId": "b53bc468-16a9-423d-eb93-95a11a222a1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    1565\n",
              "0    1435\n",
              "Name: 1, dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "N = 3000\n",
        "batch_1 = df[:N]\n",
        "batch_1[1].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQFlDhgrPrjH"
      },
      "source": [
        "Loading the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLA6F8jBPnQ0",
        "outputId": "09b03391-11d6-4a56-8ec2-4a6e6d09a4af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
        "\n",
        "# Loading pre-trained models/tokenizers\n",
        "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
        "model = model_class.from_pretrained(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YArGSxCnPzwy"
      },
      "outputs": [],
      "source": [
        "# Transform the text to the format acceptable for BERT\n",
        "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjkpGcLdP7LV"
      },
      "outputs": [],
      "source": [
        "assert tokenized[0] == [101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3VP_gLyP_uu"
      },
      "source": [
        "Each sentence is tokenized, and in order for BERT to be able to process all the examples in one batch, it is necessary to bring all the lists to the same size using padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFRNo_-AP9MP"
      },
      "outputs": [],
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mmwW9s6QE_I"
      },
      "outputs": [],
      "source": [
        "assert np.array(padded).shape == (3000, 66)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muqY2xv-QIsP"
      },
      "source": [
        "In order not to confuse the model, it is necessary to create another variable containing a mask that will help ignore paddings during processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7Y6aQ1QGtF",
        "outputId": "b5094a22-d38f-465d-a93f-4567e5e9b6d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3000, 66)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "attention_mask = np.where(padded != 0, 1, 0)\n",
        "attention_mask.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LWxUcbpXQLR6"
      },
      "outputs": [],
      "source": [
        "assert len(attention_mask[0] == 1) == 66"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foG1C16hQT6f"
      },
      "source": [
        "## Getting embeddings of offers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sAr_LXWQYs6"
      },
      "source": [
        "The model() function runs sentences through BERT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u209mwGK0GPu"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "hr-IZUS70j5Z",
        "outputId": "c7001879-2df3-4ccb-c84d-30490dd44c98"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tesla K80'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.get_device_name(0) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FcEisfiQQi3"
      },
      "outputs": [],
      "source": [
        "input_ids = torch.tensor(padded).cuda()\n",
        "attention_mask = torch.tensor(attention_mask).cuda()\n",
        "model = model.to(device)\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTygLVsJQbzB",
        "outputId": "603f070d-4296-490c-8244-106f308d5244"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3000, 66, 768])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "last_hidden_states[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffNNscyNQrkv"
      },
      "outputs": [],
      "source": [
        "features = last_hidden_states[0][:,0,:].cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDWOEvjCQ5r2"
      },
      "outputs": [],
      "source": [
        "# we save the labels of positive and negative sentences to the labels variable\n",
        "labels = batch_1[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5hGnzH6RBpv"
      },
      "source": [
        "## Divide the data into train and test for classification and select parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViAM7ZyoRCI7"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWbVw1MhRG5_",
        "outputId": "58967b10-9330-4262-f33c-933f9722fe52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "best parameters:  {'C': 5.263252631578947}\n",
            "best scrores:  0.8271111111111111\n"
          ]
        }
      ],
      "source": [
        "parameters = {'C': np.linspace(0.0001, 100, 20)}\n",
        "grid_search = GridSearchCV(LogisticRegression(), parameters)\n",
        "grid_search.fit(train_features, train_labels)\n",
        "\n",
        "print('best parameters: ', grid_search.best_params_)\n",
        "print('best scrores: ', grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAxcrP0xRRKp"
      },
      "outputs": [],
      "source": [
        "assert grid_search.best_params_['C'].round(2) == 5.26"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZTOC865RRx_",
        "outputId": "86f1944a-3104-4be5-b046-b71fc9ef4eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(C=5.263252631578947)"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf = LogisticRegression(C=grid_search.best_params_['C'])\n",
        "lr_clf.fit(train_features, train_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck2EUmMJRPBR"
      },
      "source": [
        "## Quality estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCm6IO85RVXH",
        "outputId": "297b1757-82e2-4f31-98ce-772dee5e14cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.828"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lr_clf.score(test_features, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNhYqbxWRXjk"
      },
      "source": [
        "For the purity of the experiment, we will find out the quality of the random classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pX6RwKERaRe",
        "outputId": "452265d6-c68d-4b87-c8fb-5319d45fc844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dummy classifier score: 0.523 (+/- 0.00)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "\n",
        "scores = cross_val_score(clf, train_features, train_labels)\n",
        "print(\"Dummy classifier score: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ANLP_lab3_Roman_Bezaev.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
